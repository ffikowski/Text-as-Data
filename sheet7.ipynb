{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "74f48c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem import *\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59b7337",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "981fe60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('C:/Users/felix/Documents/TU Dortmund/Text as Data/Sheet7/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe88f93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data[\"review\"], data[\"sentiment\"], test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f93d3c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57754df",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f805ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_preprocessing(document):\n",
    "    \"\"\"\n",
    "    This function performs for a single text all preprocessing steps\n",
    "    parameter: text as string\n",
    "    output: list of that contains the preprocessed tokens\n",
    "    \"\"\"\n",
    "    \n",
    "    # preprosessing of the stopwords:\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    stop_words = list(set(stopwords.words('english')))\n",
    "    \n",
    "    preprocessed_stop_words = []\n",
    "    \n",
    "    for k in np.arange(len(stop_words)):\n",
    "        text= \"\"\n",
    "        for i in np.arange(len(stop_words[k])):\n",
    "            if stop_words[k][i].isalpha() or stop_words[k][i].isspace():\n",
    "                text += stop_words[k][i].lower()\n",
    "        text = lemmatizer.lemmatize(text)\n",
    "        preprocessed_stop_words.append(text)\n",
    "    \n",
    "    # preprosessing of the actual text\n",
    "    \n",
    "    # list containing the regexes to clean the texts for not wanted pattern\n",
    "    \n",
    "    # list to save the preprocessed text\n",
    "    preprocessed_document = []\n",
    "\n",
    "    # remove non-alphabetical chars except space and split the text into a list of tokens\n",
    "    text= \"\"\n",
    "    for i in np.arange(len(document)):\n",
    "        if document[i].isalpha() or document[i].isspace():\n",
    "            text += document[i].lower()\n",
    "    text_split = text.split()\n",
    "\n",
    "    # lemmatize each token and remove it if it is part of the stopwords\n",
    "    #print(\"Before:\",len(text_split))\n",
    "    for i in text_split:\n",
    "        i = lemmatizer.lemmatize(i)\n",
    "        if i not in preprocessed_stop_words:\n",
    "            preprocessed_document.append(i)\n",
    "            \n",
    "    #print(\"After:\",len(preprocessed_document))\n",
    "    \n",
    "    return preprocessed_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8b20ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_preprocessing(corpus):\n",
    "    \"\"\"\n",
    "    This function performs for a list of texts all preprocessing steps\n",
    "    parameter: list of texts\n",
    "    output: list of lists containing where each contained lists contains the preprocessed tokens\n",
    "    \"\"\"\n",
    "    \n",
    "    preprocessed_corpus = [single_preprocessing(k) for k in corpus]\n",
    "\n",
    "    return preprocessed_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "703d0f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_preprocessed = nested_preprocessing(X_train.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bcf2188",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_preprocessed = nested_preprocessing(X_test.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83db32f5",
   "metadata": {},
   "source": [
    "## Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "229f20cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tagged = [TaggedDocument(doc, [i]) for i, doc in enumerate(X_train_preprocessed)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "264ecf79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TaggedDocument(words=['figure', 'alternate', 'reality', 'teen', 'flickmore', 'precisely', 'ferris', 'bueller', 'type', 'character', 'leader', 'cheat', 'ring', 'yeah', 'know', 'meant', 'compared', 'ferris', 'bueller', 'least', 'orangestooranges', 'way', 'nonethelessbr', 'br', 'bottomline', 'galaxy', 'away', 'even', 'even', 'minor', 'classic', 'watchable', 'though', 'expecting', 'much', 'said', 'main', 'character', 'charm', 'premise', 'wear', 'thin', 'writing', 'clever', 'movie', 'deliver', 'enough', 'laugh', 'twist', 'tension', 'keep', 'interest', 'br', 'br', 'honest', 'continue', 'watchingwatching', 'hope', 'see', 'anything', 'suddenly', 'clicked', 'stylish', 'recommend', 'movie', 'btw', 'seems', 'odd', 'see', 'mary', 'tyler', 'moore', 'principal', 'truly', 'miscast', 'hope', 'paycheck', 'inordinately', 'big'], tags=[0]), TaggedDocument(words=['kind', 'movie', 'want', 'good', 'suck', 'first', 'thing', 'hell', 'punk', 'trying', 'school', 'think', 'kid', 'seem', 'realize', 'gravity', 'situation', 'deker', 'guy', 'say', 'girl', 'responsibility', 'ask', 'want', 'go', 'back', 'right', 'give', 'gun', 'wheel', 'chair', 'dude', 'want', 'go', 'alone', 'repair', 'phone', 'line', 'responsibility', 'understand', 'poor', 'actor', 'must', 'pay', 'food', 'give', 'money', 'take', 'make', 'stupid', 'movie', 'like', 'give', 'money', 'charity', 'oh', 'yea', 'none', 'know', 'aim', 'stupid', 'punk', 'guy', 'shoot', 'cafeteria', 'nowhere', 'like', 'crazy', 'want', 'look', 'professional', 'suck', 'one', 'thing', 'believe', 'emergency', 'exit', 'school', 'kid', 'trying', 'several', 'door', 'locked', 'happens', 'fire', 'dumas', 'security', 'guard', 'dead', 'illegal', 'emergency', 'exit', 'school', 'anyway', 'lot', 'say', 'would', 'long', 'spent', 'time', 'life', 'watch', 'crap'], tags=[1]), TaggedDocument(words=['far', 'worst', 'movie', 'ive', 'ever', 'seen', 'thats', 'compared', 'alexander', 'fortress', 'new', 'worldbr', 'br', 'go', 'back', 'blockbuster', 'ask', 'money', 'back', 'along', 'compensation', 'truly', 'traumatic', 'experience', 'first', 'ten', 'minute', 'changing', 'zoom', 'widescreen', 'tv', 'actor', 'seemed', 'screen', 'think', 'possible', 'make', 'bad', 'film', 'day', 'age', 'wrong', 'typing', 'message', 'ive', 'thought', 'good', 'reason', 'buy', 'movie', 'joke', 'present', 'xmas', 'im', 'blaming', 'mr', 'one', 'picked', 'thanks', 'babebr', 'br', 'warneda', 'true', 'shocker', 'round'], tags=[2]), TaggedDocument(words=['awful', 'awful', 'awfulbr', 'br', 'loved', 'original', 'film', 'funny', 'charming', 'heart', 'piece', 'junk', 'none', 'thingsbr', 'br', 'reused', 'joke', 'original', 'film', 'stupid', 'plot', 'bad', 'animation', 'different', 'voice', 'exception', 'kronk', 'yzma', 'sound', 'nothing', 'like', 'one', 'original', 'especially', 'pacha', 'shudderbr', 'br', 'character', 'model', 'animation', 'flat', 'boring', 'bad', 'job', 'aroundbr', 'br', 'kuzco', 'jerk', 'thought', 'reformed', 'since', 'tv', 'spin', 'offs', 'loyal', 'original', 'roll', 'eyesbr', 'br', 'im', 'sorry', 'nothing', 'redeemable', 'allbr', 'br', 'avoid', 'cost'], tags=[3]), TaggedDocument(words=['fragile', 'carne', 'great', 'period', 'although', 'sometimes', 'hesitantly', 'directed', 'marred', 'longueur', 'hotel', 'du', 'nord', 'full', 'faded', 'charm', 'beauty', 'typical', 'french', 'film', 'late', 'well', 'relative', 'lightness', 'touch', 'unusual', 'director', 'great', 'virtue', 'cramped', 'interior', 'broken', 'gliding', 'complex', 'delicious', 'camera', 'movement', 'melancholy', 'deployment', 'light', 'shade', 'remarkable', 'wistful', 'set', 'alexander', 'trauner', 'evocative', 'title', 'suggests', 'take', 'shaping', 'personality', 'quietly', 'mournful', 'music', 'maurice', 'jaubert', 'seemingly', 'casual', 'plot', 'romance', 'tragedy', 'fatalism', 'cast', 'noose', 'character', 'extraordinary', 'performance', 'greatest', 'player', 'time', 'case', 'louis', 'jouvet', 'arlettybr', 'br', 'fact', 'film', 'biggest', 'failing', 'find', 'astonished', 'someone', 'usually', 'didactically', 'minimises', 'importance', 'admit', 'script', 'plenty', 'wit', 'poignancy', 'without', 'poetry', 'irony', 'regular', 'carne', 'collaborator', 'jacques', 'prevert', 'brought', 'best', 'film', 'cannot', 'avoid', 'slipping', 'cliche', 'even', 'cliche', 'hindsightbr', 'br', 'ostensibly', 'set', 'boarding', 'house', 'film', 'set', 'opening', 'idea', 'community', 'two', 'interconnecting', 'tale', 'doomed', 'love', 'emotional', 'metaphysical', 'actual', 'isolation', 'doomed', 'love', 'scenario', 'one', 'work', 'least', 'well', 'annabella', 'beautiful', 'good', 'tragic', 'aumonts', 'callowness', 'brilliantly', 'appropriate', 'though', 'may', 'nature', 'obtrudes', 'real', 'felt', 'romance', 'maybe', 'find', 'hard', 'sympathise', 'couple', 'young', 'attractive', 'month', 'racked', 'despair', 'shoot', 'highflown', 'line', 'rather', 'embarrassing', 'course', 'affair', 'meant', 'plausible', 'symbolic', 'youth', 'hope', 'possibility', 'crushed', 'france', 'maybe', 'france', 'despairing', 'resigned', 'waiting', 'death', 'symbol', 'truly', 'powerful', 'must', 'convince', 'narrative', 'level', 'feel', 'quite', 'herebr', 'br', 'save', 'plot', 'connection', 'story', 'edmond', 'character', 'linked', 'great', 'tradition', 'french', 'gangster', 'although', 'learn', 'gradually', 'killer', 'hiding', 'living', 'prostitute', 'played', 'arletty', 'dobbed', 'accomplice', 'previous', 'role', 'theatricality', 'position', 'crucial', 'one', 'set', 'trait', 'hiding', 'assumed', 'complete', 'opposite', 'living', 'rather', 'aimless', 'life', 'profoundly', 'shaken', 'lover', 'pact', 'becomes', 'fatalistic', 'realising', 'folly', 'trying', 'cheat', 'deathbr', 'br', 'way', 'admission', 'one', 'le', 'person', 'collection', 'sign', 'death', 'unavoidable', 'reality', 'powerful', 'masculinity', 'must', 'succumb', 'edmond', 'like', 'romantic', 'prototype', 'melville', 'clinical', 'killer', 'one', 'exception', 'give', 'briefly', 'hope', 'delusion', 'strenghtens', 'thats', 'much', 'unbearable', 'irony', 'fatal', 'resolvebr', 'br', 'could', 'trite', 'truly', 'amazing', 'performance', 'louis', 'jouvet', 'studied', 'theatrical', 'work', 'college', 'first', 'taste', 'screen', 'talent', 'reveals', 'worthy', 'great', 'grant', 'mastroianni', 'clift', 'mason', 'mitchum', 'cotten', 'giving', 'quiet', 'nobility', 'role', 'conception', 'needle', 'say', 'allegorical', 'actual', 'person', 'edmond', 'begin', 'film', 'minor', 'supporting', 'character', 'emerges', 'tragic', 'hero', 'force', 'like', 'major', 'actor', 'jouvets', 'brilliance', 'lie', 'concealsbr', 'br', 'formal', 'level', 'amazes', 'carnes', 'grasping', 'ten', 'year', 'flourishing', 'technique', 'great', 'hollywood', 'melodrama', 'sirk', 'ophuls', 'ray', 'minnelli', 'although', 'theatricality', 'lack', 'fluidity', 'cleareyed', 'beauty', 'siercks', 'contemporary', 'german', 'melodrama', 'check', 'masterpiece', 'zu', 'neuen', 'ufern', 'la', 'habenera', 'carnes', 'style', 'truly', 'fit', 'theme', 'entrapment', 'paralysis', 'resignationbr', 'br', 'film', 'principle', 'motif', 'water', 'credit', 'float', 'dissolve', 'hotel', 'stand', 'waterway', 'instead', 'renoir', 'open', 'river', 'possibility', 'canal', 'stagnant', 'manmade', 'going', 'nowhere', 'film', 'begin', 'end', 'setting', 'never', 'change', 'except', 'one', 'brief', 'interlude', 'escapee', 'doomed', 'return', 'character', 'escape', 'death', 'entrapment', 'emphasised', 'narrow', 'room', 'occupy', 'wall', 'frame', 'hold', 'captive', 'window', 'look', 'escape', 'never', 'achieve', 'hope', 'end', 'therefore', 'profoundly', 'romantically', 'compromised'], tags=[4]), TaggedDocument(words=['one', 'time', 'favorite', 'cheap', 'corny', 'vampire', 'b', 'movie', 'br', 'br', 'calvin', 'klein', 'underwear', 'modeloh', 'mean', 'stefan', 'good', 'vampire', 'return', 'transylvania', 'ascend', 'throne', 'vampiric', 'royalty', 'manicureimpaired', 'eternally', 'drooling', 'half', 'brother', 'radu', 'plan', 'killed', 'father', 'vampire', 'king', 'radu', 'set', 'sight', 'stefan', 'stefans', 'new', 'mortal', 'girlfriend', 'michelle', 'two', 'pretty', 'friend', 'allpowerful', 'bloodstonebr', 'br', 'okay', 'scenery', 'beautiful', 'shot', 'location', 'transylfrickenvania', 'gosh', 'sake', 'actress', 'great', 'shake', 'stefan', 'heroic', 'vampire', 'charming', 'refrigerated', 'fireplace', 'poker', 'care', 'one', 'reason', 'watch', 'movie', 'name', 'radu', 'physical', 'homage', 'nosferatu', 'best', 'line', 'movie', 'spoken', 'raspy', 'voice', 'man', 'smoke', 'ten', 'pack', 'cigarette', 'day', 'cemetery', 'festival', 'scene', 'one', 'best', 'scene', 'film', 'radu', 'slowly', 'approach', 'camera', 'reveals', 'grinning', 'slobbering', 'face', 'world', 'see', 'found', 'cheering', 'collected', 'victim', 'taunted', 'perfect', 'brother', 'maybe', 'im', 'sicko', 'questionable', 'taste', 'men', 'aside', 'highly', 'recommend', 'film', 'vampire', 'enthusiast', 'original', 'fun', 'radu', 'one', 'best', 'vampire', 'ive', 'seen', 'long', 'timemuch', 'fun', 'stiff', 'tragic', 'whining', 'undead', 'brat', 'endlessly', 'grace', 'horror', 'screen', 'day', 'radu', 'enjoys', 'sadism', 'never', 'apologizes', 'vampire'], tags=[5]), TaggedDocument(words=['hawked', 'offensive', 'movie', 'ever', 'guaranteed', 'offend', 'everyone', 'guess', 'worked', 'im', 'offended', 'shelled', 'money', 'rent', 'two', 'friend', 'bored', 'decided', 'see', 'bull', 'movie', 'saw', 'tv', 'true', 'curse', 'comedy', 'central', 'network', 'pushed', 'garbage', 'u', 'far', 'worst', 'movie', 'ive', 'seen', 'since', 'hollow', 'man', 'generally', 'avoid', 'crappy', 'one', 'got', 'sucked', 'one', 'since', 'beaten', 'prick', 'suggest', 'rent', 'movie', 'picking', 'privilege', 'revoked', 'nothing', 'remotely', 'funny', 'movieeven', 'adventure', 'dickman', 'scene', 'sophomoric', 'best', 'color', 'ped', 'thought', 'maybe', 'production', 'value', 'crap', 'important', 'reasonnoit', 'sucked', 'never', 'watch', 'reason', 'whatsoever', 'even', 'copious', 'amount', 'illegal', 'substance', 'would', 'movie', 'funny', 'thats', 'saying', 'alot', 'please', 'love', 'holy', 'cherish', 'sanity', 'never', 'view', 'movie', 'many', 'thing', 'stupid', 'pointless', 'worthless', 'name', 'main', 'thing', 'aiming', 'offensively', 'funny', 'failed', 'miserably', 'crash', 'burn'], tags=[6]), TaggedDocument(words=['production', 'value', 'video', 'poor', 'unwatchable', 'performance', 'took', 'second', 'place', 'overwhelmingly', 'creative', 'hijinks', 'studio', 'wank', 'thirty', 'special', 'effect', 'per', 'minute', 'filmed', 'cloud', 'smoke', 'one', 'two', 'second', 'duration', 'per', 'shot', 'frequently', 'background', 'spotlight', 'shine', 'directly', 'camera', 'lighting', 'terrible', 'filming', 'constant', 'zooming', 'total', 'lack', 'visual', 'continuity', 'may', 'good', 'dancing', 'available', 'live', 'audience', 'video', 'viewer', 'never', 'know'], tags=[7]), TaggedDocument(words=['late', 'im', 'running', 'short', 'vocabulary', 'describe', 'film', 'beautiful', 'heartbreaking', 'begging', 'forgiveness', 'cringe', 'cliche', 'robin', 'tunney', 'amazing', 'job', 'portraying', 'young', 'woman', 'clutch', 'tourette', 'syndrome', 'character', 'absolutely', 'sincere', 'convincing', 'follow', 'career', 'wherever', 'go', 'film'], tags=[8]), TaggedDocument(words=['saw', 'movie', 'came', 'recall', 'scariest', 'scene', 'big', 'bird', 'eating', 'men', 'dangling', 'helplessly', 'parachute', 'right', 'air', 'horror', 'horrorbr', 'br', 'young', 'kid', 'going', 'cheesy', 'b', 'film', 'saturday', 'afternoon', 'still', 'tired', 'formula', 'monster', 'type', 'movie', 'usually', 'included', 'hero', 'beautiful', 'woman', 'might', 'daughter', 'professor', 'happy', 'resolution', 'monster', 'died', 'end', 'care', 'much', 'romantic', 'angle', 'year', 'old', 'predictable', 'plot', 'love', 'unintentional', 'humorbr', 'br', 'year', 'later', 'saw', 'psycho', 'came', 'loved', 'star', 'janet', 'leigh', 'bumped', 'early', 'film', 'sat', 'took', 'notice', 'point', 'since', 'screenwriter', 'making', 'story', 'make', 'scary', 'possible', 'wellworn', 'formula', 'rule'], tags=[9])]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_tagged[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54cd76f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(vector_size=100, window=5, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05d8293e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(X_train_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e46b4a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(X_train_tagged, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23d63024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.04145692 -0.00565632  0.02075837  0.02224232 -0.01171277 -0.0307511\n",
      "  0.03952111  0.0463496  -0.00518927 -0.01438788  0.0129357  -0.00716421\n",
      " -0.00222433  0.00144624  0.00865692  0.0129415   0.01924692 -0.01864611\n",
      "  0.01343995 -0.05659904  0.03036925 -0.01120047  0.02603097  0.0167676\n",
      "  0.0020928   0.0243952  -0.0316448  -0.03207208 -0.01274072 -0.00356369\n",
      " -0.00885206 -0.00875334  0.04403827 -0.01760861  0.0308297   0.01579852\n",
      " -0.00995274 -0.008655   -0.01449026 -0.01495527 -0.00687278  0.03317825\n",
      "  0.00052388 -0.01839344  0.01201198 -0.01223186 -0.0439086  -0.00844268\n",
      "  0.01295803  0.03021282  0.0280003   0.03259393 -0.00434075 -0.01242853\n",
      " -0.00465453 -0.00948307  0.01433225 -0.02618631 -0.03318497 -0.01225872\n",
      " -0.01180308  0.00276462  0.00507419 -0.00729723 -0.02002504  0.0210344\n",
      "  0.00888676  0.03964304 -0.01209769  0.00197799 -0.00405097  0.03038548\n",
      "  0.01193575 -0.0134522   0.02560717 -0.00772716  0.02457949 -0.00699022\n",
      " -0.02493479 -0.02401142 -0.00986655  0.01176244  0.01769421  0.04063128\n",
      "  0.00121715  0.01639261  0.00432184 -0.01368213 -0.00636069  0.01019066\n",
      "  0.017384    0.00126674  0.00829911  0.00319728  0.04830195 -0.00862268\n",
      " -0.01072234 -0.01287626 -0.01240914  0.00787688]\n"
     ]
    }
   ],
   "source": [
    "vector = model.infer_vector(X_train_preprocessed[0])\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "874eb7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_embedding = [model.infer_vector(X_train_preprocessed[i]) for i, doc in enumerate(X_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ecce9373",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final = np.stack(X_train_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02ee86ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37500, 100)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85467953",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=0).fit(X_train_final, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90fc79fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_embedding = [model.infer_vector(X_test_preprocessed[i]) for i, doc in enumerate(X_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14a4e1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_final = np.stack(X_test_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88cc862b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ad0417d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.73      0.74      6157\n",
      "    positive       0.75      0.76      0.75      6343\n",
      "\n",
      "    accuracy                           0.75     12500\n",
      "   macro avg       0.75      0.75      0.75     12500\n",
      "weighted avg       0.75      0.75      0.75     12500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62034bcb",
   "metadata": {},
   "source": [
    "## Task 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f9688187",
   "metadata": {},
   "outputs": [],
   "source": [
    "wkwsci = pd.read_excel('C:/Users/felix/Documents/TU Dortmund/Text as Data/Sheet7/WKWSCI.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8ac6d020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     term  POS  sentiment\n",
      "0       a  det          0\n",
      "1    a.d.  adv          0\n",
      "2  a.k.a.  adv          0\n",
      "3    a.m.  adj          0\n",
      "4    a.m.  adv          0\n"
     ]
    }
   ],
   "source": [
    "print(wkwsci.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c49d7a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wkwsci_word_list = wkwsci['term'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d6f1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "wkwsci[\"term_preprocessed\"] = word_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ae41f450",
   "metadata": {},
   "outputs": [],
   "source": [
    "wkwsci_dict = dict(zip(wkwsci.term, wkwsci.sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f34b9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_scores = []\n",
    "\n",
    "for i in np.arange(len(X_test)):\n",
    "    X_test_list = X_test.to_list()\n",
    "    text_split = X_test_list[i].split()\n",
    "    sentiment_score = 0\n",
    "    for k in np.arange(len(text_split)):\n",
    "        \n",
    "        for key, value in wkwsci_dict.items():\n",
    "            if text_split[k] == key:\n",
    "                sentiment_score+=value\n",
    "    sentiment_scores.append(sentiment_score)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1cfa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_sent = ['positive' if score >0 else 'negative' for score in sentiment_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbf6ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_sent))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
